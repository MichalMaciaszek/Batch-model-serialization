{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import average_precision_score\n",
    "import sklearn.metrics as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = load_svmlight_file(\"cv5-1.libsvm\")\n",
    "    return data[0], data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic = LogisticRegression()\n",
    "# penalty = ['l2', 'l1']\n",
    "# C = [0.1, 1, 0.01, 10.0]\n",
    "# dual = [True, False]\n",
    "# class_weight = ['balanced', None]\n",
    "# solver = ['liblinear', 'lbfgs', 'sag']\n",
    "# max_iter = [2000]\n",
    "# hyperparameters = dict(C=C, penalty=penalty, max_iter=max_iter)\n",
    "# find = GridSearchCV(logistic, hyperparameters, cv=10, verbose=0)\n",
    "# best_model = find.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=2000, class_weight=\"balanced\", C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=2000, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos_clf = model.predict_proba(x_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52673099, 0.52952282, 0.61738208, ..., 0.45415205, 0.32904168,\n",
       "       0.01913975])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_pos_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80     62238\n",
      "         1.0       0.01      0.52      0.01       250\n",
      "\n",
      "    accuracy                           0.67     62488\n",
      "   macro avg       0.50      0.60      0.41     62488\n",
      "weighted avg       0.99      0.67      0.80     62488\n",
      "\n",
      "0.6709608244782999\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print( classification_report(y_test, predictions) )\n",
    "print( accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005206548283978025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision = average_precision_score(y_test, predictions)\n",
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6709608244782999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, predictions, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_save = \"batch.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"truth\": y_test, \"predictions\": prob_pos_clf  })\n",
    "df = df.astype({\"truth\": int})\n",
    "df.to_csv(name_to_save, sep=\" \", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.526731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.529523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.617382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.486996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62483</th>\n",
       "      <td>0</td>\n",
       "      <td>0.261733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62484</th>\n",
       "      <td>0</td>\n",
       "      <td>0.486578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62485</th>\n",
       "      <td>0</td>\n",
       "      <td>0.454152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62486</th>\n",
       "      <td>0</td>\n",
       "      <td>0.329042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62487</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62488 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       truth  predictions\n",
       "0          0     0.526731\n",
       "1          0     0.529523\n",
       "2          0     0.617382\n",
       "3          0     0.486996\n",
       "4          0     0.385700\n",
       "...      ...          ...\n",
       "62483      0     0.261733\n",
       "62484      0     0.486578\n",
       "62485      0     0.454152\n",
       "62486      0     0.329042\n",
       "62487      0     0.019140\n",
       "\n",
       "[62488 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skompiler import skompile\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cebula\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Cebula\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Cebula\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.decomposition.pca module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.decomposition. Anything that cannot be imported from sklearn.decomposition is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pfa_json = skompile(model.predict).to('pfa/json')\n",
    "pfa_just = skompile(model.predict).to('pfa')\n",
    "pfa_yaml = skompile(model.predict).to('pfa/yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': {'type': 'record',\n",
       "  'name': 'Input',\n",
       "  'fields': [{'name': 'x', 'type': {'type': 'array', 'items': 'double'}}]},\n",
       " 'output': {'type': 'double'},\n",
       " 'action': {'u.step': {'+': [{'u.vdot': [{'type': {'type': 'array',\n",
       "        'items': 'double'},\n",
       "       'value': [-0.5129286673571601,\n",
       "        -0.27739522706564007,\n",
       "        -0.5003502949294379,\n",
       "        -0.8429405676374484,\n",
       "        0.38134794245883624,\n",
       "        0.12797433065071004,\n",
       "        -0.3017365032060635,\n",
       "        -0.06637870505999018,\n",
       "        -0.0839166102283698,\n",
       "        0.6413147839740865,\n",
       "        0.6893631039701519,\n",
       "        -0.13624031428253264,\n",
       "        0.36186398224133254,\n",
       "        -0.3802457130851197,\n",
       "        0.05789932260950891,\n",
       "        -0.28878817110703636,\n",
       "        0.09725576456059976,\n",
       "        0.06685899628179312,\n",
       "        0.3567115901021604,\n",
       "        0.47286161065956106,\n",
       "        0.05619207141873824,\n",
       "        0.3019419092925552,\n",
       "        -0.1112422249459121,\n",
       "        -0.11600499314559523,\n",
       "        -0.09608959821983615,\n",
       "        -0.25115803455116004,\n",
       "        -0.4701755111299268,\n",
       "        -0.1884720454781663,\n",
       "        -0.4776821748530858,\n",
       "        -0.15424384222197965,\n",
       "        -0.17623365460877985,\n",
       "        0.9311503398332387,\n",
       "        -0.004221117284603748,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.1480000124401347,\n",
       "        1.386390071917582,\n",
       "        0.0,\n",
       "        -0.005208059651306606,\n",
       "        0.10120377070344413,\n",
       "        0.0,\n",
       "        0.062495551568885616,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.6521870958077939,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.1097483342025633,\n",
       "        0.388843690794534,\n",
       "        0.0,\n",
       "        -0.20077439085991328,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.8006273403827617,\n",
       "        0.2910238239160874,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.6990770717856628,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.6593385648771861,\n",
       "        0.42263117451820603,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.2709719578049905,\n",
       "        0.0,\n",
       "        -0.44029770864923207,\n",
       "        -0.201483970238784,\n",
       "        0.11990154848065565,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.1776970589979594,\n",
       "        0.0,\n",
       "        -0.36188677736956115,\n",
       "        -0.33904402741119843,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.43770125598216064,\n",
       "        0.07422784277300731,\n",
       "        0.13907798010753308,\n",
       "        -0.057567571039808176,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.4456446644188514,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.24648366564444182,\n",
       "        0.0,\n",
       "        -0.009534523241404937,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.20491702649589877,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.15884214135569455,\n",
       "        0.4230646320883181,\n",
       "        0.0,\n",
       "        -1.422978174034325,\n",
       "        -0.24629666329871616,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.4853716361584546,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.4233341396585187,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.3830020647838761,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.33628706291053834,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.43770125598216064,\n",
       "        0.07422784277300731,\n",
       "        0.13907798010753308,\n",
       "        0.7322574652628303,\n",
       "        -0.020113447660421783,\n",
       "        -0.14514682391888717,\n",
       "        0.04351981750391639,\n",
       "        0.22666544888781606,\n",
       "        0.4704628552719892,\n",
       "        -0.07862518956371031,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -1.6475548322546278,\n",
       "        -0.22912692551084832,\n",
       "        0.6335987469774019,\n",
       "        -0.18051478998112677,\n",
       "        0.5068060053655158,\n",
       "        -0.3611297774958795,\n",
       "        0.568873671120257,\n",
       "        -0.3977466146291984,\n",
       "        -0.056174174205069184,\n",
       "        -0.3648792356047766,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -1.5633348878729476,\n",
       "        -0.2933604951476491,\n",
       "        -0.6830723454215814,\n",
       "        0.8243428605861172,\n",
       "        0.42883717103268787,\n",
       "        0.5125471896769799,\n",
       "        -0.4058271234288946,\n",
       "        0.7009195780397621,\n",
       "        0.4410916004077289,\n",
       "        -1.8357137152308645,\n",
       "        0.0,\n",
       "        1.3012800589675395,\n",
       "        0.49201597075998577,\n",
       "        -0.6559212821959113,\n",
       "        -0.99494974692069,\n",
       "        -0.7920913161313656,\n",
       "        -0.5689493505208199,\n",
       "        -0.38884278740081796,\n",
       "        1.736566880517928,\n",
       "        0.446255937738916,\n",
       "        0.15879621756662557,\n",
       "        0.05727367086704128,\n",
       "        0.6671802253797294,\n",
       "        0.2670766603149174,\n",
       "        0.623326014281753,\n",
       "        -0.46153277825246497,\n",
       "        -0.2793216758343105,\n",
       "        -0.5378131225701427,\n",
       "        0.6089179529887856,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.6185656189321839,\n",
       "        -1.0974885681684334,\n",
       "        1.0337378992575474,\n",
       "        0.6243871745030419,\n",
       "        0.9550579757050545,\n",
       "        -2.0204409924230164,\n",
       "        0.6320055040845602,\n",
       "        0.4502597152327738,\n",
       "        -0.04299265127638472,\n",
       "        1.2549813912894157,\n",
       "        0.0,\n",
       "        -0.7507354316021818,\n",
       "        1.184615117561797,\n",
       "        0.8626675708395961,\n",
       "        -0.05584633330322065,\n",
       "        -0.260905203249808,\n",
       "        -0.02750449042126939,\n",
       "        1.1981513639533155,\n",
       "        0.0,\n",
       "        -2.391685918767591,\n",
       "        -0.05007403149857976,\n",
       "        0.7935399899427918,\n",
       "        0.6778716274257758,\n",
       "        0.4909747865135183,\n",
       "        1.1283995816355368,\n",
       "        -0.05820191215420403,\n",
       "        0.020112876554087604,\n",
       "        -0.3773265465800795,\n",
       "        -0.3677776451765529,\n",
       "        -0.05795649721283053,\n",
       "        -0.6240646862614784,\n",
       "        -0.2337994101619306,\n",
       "        0.1925307590655412,\n",
       "        0.20077825184578607,\n",
       "        0.7753820522900292,\n",
       "        0.0015056914070158234,\n",
       "        1.368955660480497,\n",
       "        -0.6395925061411565,\n",
       "        -0.5885192767890394,\n",
       "        -0.5205903202157548,\n",
       "        -0.30578829094942994,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.014788341733518593,\n",
       "        -0.23453422512404276,\n",
       "        1.6829769260846354,\n",
       "        0.32257083662125063,\n",
       "        -0.5785094022436379,\n",
       "        1.3907399528975644,\n",
       "        0.588918337730766,\n",
       "        -0.27013791532697645,\n",
       "        -0.6286139393900368,\n",
       "        -0.6256982587357279,\n",
       "        -0.036435374663185666,\n",
       "        0.10385572167502097,\n",
       "        1.25356570744017,\n",
       "        0.6239952112208824,\n",
       "        0.5028821570821295,\n",
       "        1.1375266835708346,\n",
       "        -0.4344837371436829,\n",
       "        -1.2135725426395794,\n",
       "        -1.000620988766745,\n",
       "        -0.2932826374908768,\n",
       "        0.9126638505841679,\n",
       "        1.4861305631491715,\n",
       "        -0.3647923091120236,\n",
       "        0.3078739003566184,\n",
       "        -0.008727417724419857,\n",
       "        -1.3654957360049405,\n",
       "        0.6627475015255396,\n",
       "        -1.4091960175411298,\n",
       "        0.8047860608105767,\n",
       "        0.0,\n",
       "        -1.0752839159967613,\n",
       "        1.313844494141083,\n",
       "        0.7242185140355442,\n",
       "        -0.8128099923670934,\n",
       "        -0.2892710539178393,\n",
       "        -1.3849359719685543,\n",
       "        -0.1802188212754848,\n",
       "        -0.12169110845313072,\n",
       "        0.6193764022621094,\n",
       "        -0.5832764830084063,\n",
       "        -0.5283300796697207,\n",
       "        -0.2750264600755006,\n",
       "        -0.3891166852229594,\n",
       "        -0.33251377872489624,\n",
       "        -0.8242403423502618,\n",
       "        -0.08764046513287871,\n",
       "        -0.738785174110093,\n",
       "        -0.2076742696585781,\n",
       "        -0.9118825047413441,\n",
       "        0.677586298047394,\n",
       "        0.7833700839508975,\n",
       "        0.2813792247187593,\n",
       "        -0.2951386385206574,\n",
       "        -0.3501597809639812,\n",
       "        -0.689994887102272,\n",
       "        -0.18678262455914615,\n",
       "        0.5276652033156064,\n",
       "        -2.3639649648276437,\n",
       "        0.18878627925255367,\n",
       "        0.9987448752970877,\n",
       "        0.0,\n",
       "        3.27669701794237,\n",
       "        -0.291952857110613,\n",
       "        -0.3392566688712748,\n",
       "        -0.3380981664079838,\n",
       "        -0.3294409319372251,\n",
       "        -0.16225575180233412,\n",
       "        -0.2706199239956171,\n",
       "        -0.15760338490584944,\n",
       "        0.4230297173919733,\n",
       "        -0.13459650579247623,\n",
       "        0.19834439734906975,\n",
       "        1.0488038342276196,\n",
       "        -0.9670471323580856,\n",
       "        0.017875724344935486,\n",
       "        0.7064230724371969,\n",
       "        0.5463388005459734,\n",
       "        -0.03800472901747142,\n",
       "        -0.1384871823177647,\n",
       "        0.6430760868840655,\n",
       "        0.3536906610738128,\n",
       "        -0.9452343570355094,\n",
       "        -0.4351743344727646,\n",
       "        -0.4700524543578758,\n",
       "        0.19790388746975368,\n",
       "        0.21770113085994094,\n",
       "        0.4059854670210825,\n",
       "        0.8021970772269481,\n",
       "        0.13953353057807588,\n",
       "        -1.0308205910331227,\n",
       "        -0.6930132083189015,\n",
       "        0.0,\n",
       "        1.1776578959735464,\n",
       "        -0.27807954809440966,\n",
       "        -0.13869954094082107,\n",
       "        -0.06089809005271479,\n",
       "        -0.0232788567200186,\n",
       "        -0.03515177920868539,\n",
       "        -0.03581102839600742,\n",
       "        -0.5483167309902136,\n",
       "        -1.6069647138367316,\n",
       "        0.08257731791705714,\n",
       "        -0.5277335901596213,\n",
       "        -0.6619088385628916,\n",
       "        1.3428494144926335,\n",
       "        -0.4953008465746348,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -1.4378696077380393,\n",
       "        -0.4244518760400038,\n",
       "        -0.3994256523373519,\n",
       "        0.842288394561206,\n",
       "        -0.6644308486790409,\n",
       "        -0.03994235137021153,\n",
       "        0.5807307745466666,\n",
       "        0.5344318760661133,\n",
       "        -0.0017882789448387094,\n",
       "        1.4758771275348885,\n",
       "        -0.9039171669369312,\n",
       "        1.27866373928773,\n",
       "        -0.32915782126898396,\n",
       "        -0.009534523241404937,\n",
       "        0.0,\n",
       "        -0.6034903645568702,\n",
       "        -0.35932749241538714,\n",
       "        -0.2740227432621194,\n",
       "        -0.3730424593912343,\n",
       "        0.0,\n",
       "        -0.17242177256109098,\n",
       "        1.3062809531296178,\n",
       "        -0.23841026133476687,\n",
       "        -0.6513758147543537,\n",
       "        0.9468619457094927,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        1.5279384107804452,\n",
       "        -1.3073816939445193,\n",
       "        -0.12698034568601074,\n",
       "        0.274008225800496,\n",
       "        1.3313968803723324,\n",
       "        0.8763641731886914,\n",
       "        0.7831565569578408,\n",
       "        -0.022003744900560035,\n",
       "        -0.8602975565973158,\n",
       "        0.536273330962059,\n",
       "        0.8272077780788126,\n",
       "        0.3879460332547078,\n",
       "        1.4478051735888433,\n",
       "        1.433429564582245,\n",
       "        0.0,\n",
       "        -0.3605263613656736,\n",
       "        -1.1891764690799733,\n",
       "        -0.9857847211530554,\n",
       "        -0.380112302490162,\n",
       "        -0.9604550203636731,\n",
       "        0.9945250418639972,\n",
       "        -1.1218814779119113,\n",
       "        -0.519931779800841,\n",
       "        -0.260842793971446,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.1097483342025633,\n",
       "        0.020820576112516035,\n",
       "        -0.25881379688206824,\n",
       "        -0.7732859063658215,\n",
       "        -0.0011760213827611149,\n",
       "        0.24417321917408186,\n",
       "        1.8055631450032736,\n",
       "        -0.011643199321013273,\n",
       "        -0.3608447016873826,\n",
       "        0.9254645744069132,\n",
       "        1.0681161188703223,\n",
       "        -0.08088184743175346,\n",
       "        -0.2109770512991007,\n",
       "        -0.6486193553175592,\n",
       "        0.12079558231229513,\n",
       "        -0.1072022668320189,\n",
       "        -0.4567443581200741,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        -0.44029770864923207,\n",
       "        -0.201483970238784,\n",
       "        0.0,\n",
       "        -0.09560146371522259,\n",
       "        -1.52869356517608,\n",
       "        1.1369505339571218,\n",
       "        0.7720217209354521,\n",
       "        -0.9820888646703301,\n",
       "        -1.537212054335368,\n",
       "        0.26363148182874285,\n",
       "        -0.39648665661936977,\n",
       "        -0.28129250696062535,\n",
       "        0.3103169081001522,\n",
       "        -1.039969328133445,\n",
       "        0.5290240130443747,\n",
       "        0.25678119991111464,\n",
       "        0.2605277323154297,\n",
       "        -0.15615974940420485,\n",
       "        1.1943154494595765,\n",
       "        -1.6059018795654592,\n",
       "        -0.010841782304080606,\n",
       "        0.9038978673408067,\n",
       "        0.5285941626257319,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        0.0,\n",
       "        ...]},\n",
       "      'input.x']},\n",
       "    -3.2075165440532447]}},\n",
       " 'fcns': {'step': {'params': [{'x': 'double'}],\n",
       "   'ret': 'double',\n",
       "   'do': {'if': {'<=': ['x', 0.0]}, 'then': 0.0, 'else': 1.0}},\n",
       "  'vdot': {'params': [{'x': {'type': 'array', 'items': 'double'}},\n",
       "    {'y': {'type': 'array', 'items': 'double'}}],\n",
       "   'ret': 'double',\n",
       "   'do': {'attr': {'la.dot': [{'type': {'type': 'array',\n",
       "        'items': {'type': 'array', 'items': 'double'}},\n",
       "       'new': ['x']},\n",
       "      'y']},\n",
       "    'path': [0]}}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfa_just"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('to_deploy', 'w') as outfile:\n",
    "    json.dump(pfa_just, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
